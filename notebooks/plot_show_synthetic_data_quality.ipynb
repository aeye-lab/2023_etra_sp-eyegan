{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9e111e",
   "metadata": {},
   "source": [
    "# Notebook to plot GAN quality statistics\n",
    "* Pipeline to train models and create synthetic dataset:\n",
    "    * create data with create_event_data_from_gazebase.py\n",
    "    * train model with train_event_model.py\n",
    "    * create_synthetic_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1f507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:49:15.627680: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 14:49:17.584684: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/gcc-4.4.3/objdir/x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/:/usr/local/gcc-4.4.3/objdir/x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/::/mnt/projekte/pmlcluster/home/prasse/projects/object_detection/opencv_multicore/opencv-2.4.4/lib:/usr/local/lib:/home/prasse/work/Projekte/tmp/maxi/bin/gsl/lib:/home/prasse/anaconda3/envs/tf/lib/:/mnt/projekte/pmlcluster/home/prasse/projects/object_detection/opencv_multicore/opencv-2.4.4/lib:/usr/local/lib:/home/prasse/work/Projekte/tmp/maxi/bin/gsl/lib:/home/prasse/anaconda3/envs/tf/lib/\n",
      "2023-04-03 14:49:17.584832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/gcc-4.4.3/objdir/x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/:/usr/local/gcc-4.4.3/objdir/x86_64-unknown-linux-gnu/libstdc++-v3/src/.libs/::/mnt/projekte/pmlcluster/home/prasse/projects/object_detection/opencv_multicore/opencv-2.4.4/lib:/usr/local/lib:/home/prasse/work/Projekte/tmp/maxi/bin/gsl/lib:/home/prasse/anaconda3/envs/tf/lib/:/mnt/projekte/pmlcluster/home/prasse/projects/object_detection/opencv_multicore/opencv-2.4.4/lib:/usr/local/lib:/home/prasse/work/Projekte/tmp/maxi/bin/gsl/lib:/home/prasse/anaconda3/envs/tf/lib/\n",
      "2023-04-03 14:49:17.584844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasse/anaconda3/envs/aeye_tensorflow_minimal/lib/python3.10/site-packages/IPython/core/magics/pylab.py:162: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from sp_eyegan.model import eventGAN as eventGAN\n",
    "from sp_eyegan.model import vae_baseline as vae\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf628f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vel_to_dva(vel_data, x_start = 0,\n",
    "             y_start = 0):\n",
    "    x_vel = vel_data[:,0]\n",
    "    y_vel = vel_data[:,1]\n",
    "    x_px  = []\n",
    "    y_px  = []\n",
    "    cur_x_pos = x_start\n",
    "    cur_y_pos = y_start\n",
    "    for i in range(len(x_vel)):\n",
    "        x_px.append(cur_x_pos + x_vel[i])\n",
    "        y_px.append(cur_y_pos + y_vel[i])\n",
    "        cur_x_pos = x_px[-1]\n",
    "        cur_y_pos = y_px[-1]\n",
    "    return np.concatenate([np.expand_dims(np.array(x_px),axis=1),\n",
    "                           np.expand_dims(np.array(y_px),axis=1)],axis=1)\n",
    "\n",
    "def get_fixation_stats(input_data):\n",
    "    real_x_vels      = []\n",
    "    real_y_vels      = []\n",
    "    real_vels        = []\n",
    "    real_dispersions = []\n",
    "    cur_vel_data     = input_data\n",
    "    for i in tqdm(np.arange(cur_vel_data.shape[0])):\n",
    "        cur_vels = cur_vel_data[i]\n",
    "        cur_dva = vel_to_dva(cur_vels)\n",
    "        try:\n",
    "            end_id = np.where(np.logical_and(cur_vels[:,0] == 0,\n",
    "                                             cur_vels[:,1] ==0 ))[0][0]\n",
    "        except:\n",
    "            end_id = len(cur_vels)\n",
    "        if end_id == 0:\n",
    "            continue\n",
    "        cur_vels = cur_vels[0:end_id]\n",
    "        cur_dva = cur_dva[0:end_id]\n",
    "        x_dva = cur_dva[:,0]\n",
    "        y_dva = cur_dva[:,1]\n",
    "        real_x_vels.append(cur_vels[:,0])\n",
    "        real_y_vels.append(cur_vels[:,1])\n",
    "        \n",
    "        vels =  np.power(np.array(real_x_vels[-1]),2) +\\\n",
    "                np.power(np.array(real_y_vels[-1]),2)\n",
    "        vels = np.sqrt(vels)\n",
    "        real_vels.append(vels)\n",
    "        x_amp = np.abs(np.max(x_dva) - np.min(x_dva))\n",
    "        y_amp = np.abs(np.max(y_dva) - np.min(y_dva))\n",
    "        cur_dispersion = x_amp + y_amp\n",
    "        real_dispersions.append(cur_dispersion)\n",
    "    \n",
    "    return real_vels, real_x_vels,real_y_vels, real_dispersions\n",
    "\n",
    "\n",
    "def get_saccade_stats(input_data, max_velocity = 0.5):\n",
    "    real_x_vels      = []\n",
    "    real_y_vels      = []\n",
    "    real_vels        = []\n",
    "    real_amplitudes  = []\n",
    "    real_x_accs      = []\n",
    "    real_y_accs      = []\n",
    "    real_accs        = []\n",
    "    cur_vel_data     = input_data\n",
    "    for i in tqdm(np.arange(cur_vel_data.shape[0])):\n",
    "        cur_vels = cur_vel_data[i]\n",
    "        cur_dva = vel_to_dva(cur_vels)\n",
    "        try:\n",
    "            end_id = np.where(np.logical_and(cur_vels[:,0] == 0,\n",
    "                                             cur_vels[:,1] ==0 ))[0][0]\n",
    "        except:\n",
    "            end_id = len(cur_vels)\n",
    "        if end_id == 0:\n",
    "            continue\n",
    "        cur_vels = cur_vels[0:end_id]\n",
    "        cur_dva = cur_dva[0:end_id]\n",
    "        x_dva = cur_dva[:,0]\n",
    "        y_dva = cur_dva[:,1]\n",
    "        real_x_vels.append(cur_vels[:,0])\n",
    "        real_y_vels.append(cur_vels[:,1])\n",
    "        \n",
    "        vels =  np.power(np.array(real_x_vels[-1]),2) +\\\n",
    "                np.power(np.array(real_y_vels[-1]),2)\n",
    "        vels = np.sqrt(vels)\n",
    "        real_vels.append(vels)        \n",
    "        \n",
    "        x_accs = cur_vels[1:,0] - cur_vels[:-1,0]\n",
    "        y_accs = cur_vels[1:,1] - cur_vels[:-1,0]\n",
    "        \n",
    "        accs = np.power(np.array(x_accs),2) +\\\n",
    "                np.power(np.array(y_accs),2)\n",
    "        accs = np.sqrt(accs)\n",
    "        \n",
    "        real_x_accs.append(x_accs)\n",
    "        real_y_accs.append(y_accs)\n",
    "        real_accs.append(accs)\n",
    "        cur_complete_vels = np.sqrt(np.power(cur_vels[:,0],2) + np.power(cur_vels[:,1],2))\n",
    "        cur_complete_vels[cur_complete_vels > max_velocity] = max_velocity\n",
    "        cur_amplitude = np.sqrt(np.power(x_dva[0] - x_dva[-1],2) + np.power(y_dva[0] - y_dva[-1],2))\n",
    "        real_amplitudes.append(cur_amplitude)\n",
    "    \n",
    "    return real_vels, real_x_vels, real_y_vels, real_accs, real_x_accs, real_y_accs, np.array(real_amplitudes)\n",
    "\n",
    "\n",
    "# calculate the kl divergence\n",
    "def kl_divergence(p, q):\n",
    "    from math import log2\n",
    "    from math import sqrt\n",
    "    rel_etropies = [p[i] * log2(p[i]/q[i]) for i in range(len(p))]\n",
    "    return np.sum(np.array(rel_etropies,dtype=np.float32))\n",
    " \n",
    "# calculate the js divergence\n",
    "def js_divergence(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
    "\n",
    "\n",
    "def draw_display(dispsize: Tuple[int, int], imagefile=None) -> Tuple[pyplot.figure, pyplot.Axes]:\n",
    "    # construct screen (black background)\n",
    "    # dots per inch\n",
    "    img = image.imread(imagefile)\n",
    "    dpi = 100.0\n",
    "    # determine the figure size in inches\n",
    "    figsize = (dispsize[0]/dpi, dispsize[1]/dpi)\n",
    "    # create a figure\n",
    "    fig = pyplot.figure(figsize=figsize, dpi=dpi, frameon=False)\n",
    "    ax = pyplot.Axes(fig, [0, 0, 1, 1])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    # plot display\n",
    "    ax.axis([0, dispsize[0], 0, dispsize[1]])\n",
    "    ax.imshow(img)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "def pix2deg(pix, screenPX,screenCM,distanceCM, adjust_origin=True):\n",
    "    # Converts pixel screen coordinate to degrees of visual angle\n",
    "    # screenPX is the number of pixels that the monitor has in the horizontal\n",
    "    # axis (for x coord) or vertical axis (for y coord)\n",
    "    # screenCM is the width of the monitor in centimeters\n",
    "    # distanceCM is the distance of the monitor to the retina \n",
    "    # pix: screen coordinate in pixels\n",
    "    # adjust origin: if origin (0,0) of screen coordinates is in the corner of the screen rather than in the center, set to True to center coordinates\n",
    "    pix=np.array(pix)\n",
    "    # center screen coordinates such that 0 is center of the screen:\n",
    "    if adjust_origin: \n",
    "        pix = pix-(screenPX)/2 # pixel coordinates start with (0,0) \n",
    "    # eye-to-screen-distance in pixels of screen\n",
    "    distancePX = distanceCM*(screenPX/screenCM)\n",
    "    return np.arctan2(pix,distancePX) * 180/np.pi #  *180/pi wandelt bogenmass in grad\n",
    "\n",
    "\n",
    "def deg2pix(deg, screenPX, screenCM, distanceCM, adjust_origin = True, offsetCM = 0):\n",
    "    # Converts degrees of visual angle to pixel screen coordinates\n",
    "    # screenPX is the number of pixels that the monitor has in the horizontal\n",
    "    # screenCM is the width of the monitor in centimeters\n",
    "    # distanceCM is the distance of the monitor to the retina \n",
    "    phi = np.arctan2(1,distanceCM)*180/np.pi\n",
    "    pix = deg/(phi/(screenPX/(screenCM)))\n",
    "    if adjust_origin:\n",
    "        pix += (screenPX/2)\n",
    "    if offsetCM != 0:\n",
    "        offsetPX = offsetCM*(screenPX/screenCM)\n",
    "        pix += offsetPX\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d50f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "GPU = 0\n",
    "data_dir = 'data/'\n",
    "plot_dir = 'plots/'\n",
    "result_dir = 'results/'\n",
    "\n",
    "model_name = 'GAN'\n",
    "real_name = 'real'\n",
    "gauss_name = 'Gauss'\n",
    "\n",
    "\n",
    "# load data\n",
    "column_dict = joblib.load(data_dir + 'column_dict.joblib')\n",
    "fixation_matrix = np.load(data_dir + 'fixation_matrix_gazebase_vd_text.npy')\n",
    "saccade_matrix = np.load(data_dir  + 'saccade_matrix_gazebase_vd_text.npy')\n",
    "\n",
    "fix_window_size = fixation_matrix.shape[1]\n",
    "sac_window_size = saccade_matrix.shape[1]\n",
    "gen_kernel_sizes_fixation = [fix_window_size,8,4,2]\n",
    "gen_kernel_sizes_saccade = [sac_window_size,8,4,2]\n",
    "    \n",
    "# params for NN\n",
    "random_size = 32\n",
    "gen_filter_sizes = [16,8,4,2]\n",
    "channels = 2\n",
    "relu_in_last = False\n",
    "batch_size = 256\n",
    "\n",
    "dis_kernel_sizes = [8,16,32]\n",
    "dis_fiter_sizes = [32,64,128]\n",
    "dis_dropout = 0.3\n",
    "\n",
    "sample_size = 1000\n",
    "max_velocity = 0.5\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "model_config_fixation = {'gen_kernel_sizes':gen_kernel_sizes_fixation,\n",
    "                'gen_filter_sizes':gen_filter_sizes,\n",
    "                'dis_kernel_sizes':dis_kernel_sizes,\n",
    "                'dis_fiter_sizes':dis_fiter_sizes,\n",
    "                'dis_dropout':dis_dropout,\n",
    "                'window_size':fix_window_size,\n",
    "                'channels':channels,\n",
    "                'batch_size':batch_size,\n",
    "                'random_size':random_size,\n",
    "                'relu_in_last':relu_in_last,\n",
    "               }\n",
    "\n",
    "model_config_saccade = {'gen_kernel_sizes':gen_kernel_sizes_saccade,\n",
    "                'gen_filter_sizes':gen_filter_sizes,\n",
    "                'dis_kernel_sizes':dis_kernel_sizes,\n",
    "                'dis_fiter_sizes':dis_fiter_sizes,\n",
    "                'dis_dropout':dis_dropout,\n",
    "                'window_size':sac_window_size,\n",
    "                'channels':channels,\n",
    "                'batch_size':batch_size,\n",
    "                'random_size':random_size,\n",
    "                'relu_in_last':relu_in_last,\n",
    "               }\n",
    "\n",
    "\n",
    "fixation_path  = 'event_model/fixation_model_text'\n",
    "saccade_path   = 'event_model/saccade_model_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad508e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:49:20.996683: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:49:23.244517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11178 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "flag_train_on_gpu = True\n",
    "if flag_train_on_gpu:\n",
    "    import tensorflow as tf\n",
    "    # select graphic card\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPU)\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    config = tf.compat.v1.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1.\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tf_session = tf.compat.v1.Session(config=config)\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "    # select graphic card\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac12553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393706, 100, 6)\n",
      "(103890, 30, 6)\n"
     ]
    }
   ],
   "source": [
    "print(fixation_matrix.shape)\n",
    "print(saccade_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7cb51c",
   "metadata": {},
   "source": [
    "#### Data for statitical baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa801d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vel</th>\n",
       "      <th>type</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.494492</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.875850</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.185847</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.075208</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vel  type  frame\n",
       "0    1.494492   2.0    2.0\n",
       "1  470.000000   3.0    4.0\n",
       "2    1.875850   2.0    6.0\n",
       "3    2.185847   2.0    8.0\n",
       "4    2.075208   2.0   10.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### select model for baseline method (statistical method)\n",
    "gen_data_statitical = pd.read_csv('data/statistical_baseline_fix_data.txt',sep=';',header = None)\n",
    "gen_data_statitical.columns = ['vel','type','frame']\n",
    "gen_data_statitical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16df99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number fix points: 17889\n",
      "number sac points: 5294\n"
     ]
    }
   ],
   "source": [
    "fixation_index = 0\n",
    "saccade_index = 1\n",
    "velocities = np.array(gen_data_statitical['vel'])\n",
    "event_type = np.array(gen_data_statitical['type'])\n",
    "print('number fix points: ' + str(np.sum(event_type == fixation_index)))\n",
    "print('number sac points: ' + str(np.sum(event_type == saccade_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a60b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 56504/56504 [00:00<00:00, 703441.16it/s]\n"
     ]
    }
   ],
   "source": [
    "fix_vels_statistical = []\n",
    "sac_vels_statistical = []\n",
    "sac_acc_statistical  = []\n",
    "\n",
    "# transfrom °/s to °/ms\n",
    "scaling_factor = 1000.\n",
    "prev_event = -1\n",
    "cur_fixation = []\n",
    "cur_saccade  = []\n",
    "for i in tqdm(np.arange(len(velocities))):\n",
    "    cur_event = event_type[i]\n",
    "    cur_vel   = velocities[i]\n",
    "    if cur_event == prev_event:\n",
    "        if cur_event == fixation_index:\n",
    "            cur_fixation.append(cur_vel/scaling_factor)\n",
    "        elif cur_event == saccade_index:\n",
    "            cur_saccade.append(cur_vel/scaling_factor)\n",
    "    else:\n",
    "        if prev_event == fixation_index and len(cur_fixation) > 0:\n",
    "            fix_vels_statistical.append(np.array(cur_fixation))\n",
    "        elif prev_event == saccade_index and len(cur_saccade) > 0:\n",
    "            sac_vels_statistical.append(np.array(cur_saccade))\n",
    "            if len(cur_saccade) > 2:\n",
    "                sac_acc_statistical.append(np.array(cur_saccade)[1:] - np.array(cur_saccade)[0:-1])\n",
    "        \n",
    "        if cur_event == fixation_index:\n",
    "            cur_fixation = [cur_vel/scaling_factor]\n",
    "            cur_saccade = []\n",
    "        elif cur_event == saccade_index:\n",
    "            cur_saccade = [cur_vel/scaling_factor]\n",
    "            cur_fixation = []\n",
    "    prev_event = cur_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bd92f",
   "metadata": {},
   "source": [
    "## Evaluate Fixations\n",
    "* velocities, dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfba11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "eye_syn_fixation_data = loadmat('data/eyeSyn_velocities.mat')\n",
    "eye_syn_fixation_data = eye_syn_fixation_data['out_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b07652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a49700f",
   "metadata": {},
   "source": [
    "#### sample fixations with GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a8cce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:49:23.668190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11178 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "fix_model = eventGAN.eventGAN(model_config_fixation)\n",
    "fix_model.load_model(fixation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084ff29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:49:24.425735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-04-03 14:49:24.713681: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-03 14:49:24.716475: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([sample_size, random_size], seed = seed)\n",
    "gen_fixations = np.array(fix_model.generator(noise, training=False),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ba5adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.046509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.002635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.029683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  200000.000000\n",
       "mean        0.000072\n",
       "std         0.004561\n",
       "min        -0.046509\n",
       "25%        -0.002635\n",
       "50%         0.000125\n",
       "75%         0.002811\n",
       "max         0.029683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gen_fixations.shape)\n",
    "pd.DataFrame(gen_fixations.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f03c3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "vae_model = vae.VAE(vae.get_vae_encoder(64, 2, 2), vae.get_vae_decoder(2, 2))\n",
    "vae_model.load_model('event_model/vae_fixation_10')\n",
    "noise = tf.random.normal([sample_size * 2, 2], seed = seed)\n",
    "vae_fixations = np.array(vae_model.decoder(noise, training=False),dtype=np.float32)\n",
    "vae_fixations = np.concatenate([vae_fixations[0:sample_size],\n",
    "                                vae_fixations[sample_size:]],axis=1)\n",
    "vae_fixations = vae_fixations[:,0:100,:] -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a546ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.012177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.023295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  200000.000000\n",
       "mean        0.000527\n",
       "std         0.001529\n",
       "min        -0.012177\n",
       "25%        -0.000228\n",
       "50%         0.000267\n",
       "75%         0.001013\n",
       "max         0.023295"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_fixations.shape\n",
    "pd.DataFrame(vae_fixations.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b4ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc901dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ids        = np.random.permutation(np.arange(fixation_matrix.shape[0]))\n",
    "rand_ids_1      = rand_ids[0:sample_size]\n",
    "rand_ids_2      = rand_ids[sample_size:sample_size+sample_size]\n",
    "orig_fixations  = fixation_matrix[rand_ids_1,:,4:6]\n",
    "orig_fixations[orig_fixations > max_velocity] = max_velocity\n",
    "orig_fixations[orig_fixations < -max_velocity] = -max_velocity\n",
    "\n",
    "orig_fixations_2 = fixation_matrix[rand_ids_2,:,4:6]\n",
    "orig_fixations_2[orig_fixations_2 > max_velocity] = max_velocity\n",
    "orig_fixations_2[orig_fixations_2 < -max_velocity] = -max_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae00b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 7651.17it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 8067.18it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 6571.12it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 4132.30it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 6674.10it/s]\n"
     ]
    }
   ],
   "source": [
    "real_vels, real_x_vels, real_y_vels, real_dispersions = get_fixation_stats(orig_fixations)\n",
    "real_vels_2, real_x_vels_2, real_y_vels_2, real_dispersions_2 = get_fixation_stats(orig_fixations_2)\n",
    "fake_vels, fake_x_vels, fake_y_vels, fake_dispersions = get_fixation_stats(gen_fixations)\n",
    "eyesyn_vels, eyesyn_x_vels, eyesyn_y_vels, eyesyn_dispersions =  get_fixation_stats(eye_syn_fixation_data)\n",
    "vae_vels, vae_x_vels, vae_y_vels, vae_dispersions = get_fixation_stats(vae_fixations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b7334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 8043.05it/s]\n"
     ]
    }
   ],
   "source": [
    "x_vel_mean = np.nanmean([item for sublist in real_x_vels for item in sublist])\n",
    "x_vel_std = np.nanstd([item for sublist in real_x_vels for item in sublist])\n",
    "\n",
    "y_vel_mean = np.nanmean([item for sublist in real_y_vels for item in sublist])\n",
    "y_vel_std = np.nanstd([item for sublist in real_y_vels for item in sublist])\n",
    "gauss_fixations = np.concatenate([np.random.normal(x_vel_mean,x_vel_std,(sample_size,fix_window_size,1)),\n",
    "                                np.random.normal(y_vel_mean,y_vel_std,(sample_size,fix_window_size,1))],axis=2)\n",
    "gauss_vels, gauss_x_vels, gauss_y_vels, gauss_dispersions = get_fixation_stats(gauss_fixations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f9a1daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000588988012629895 0.012758497782424435\n",
      "-6.230466548694232e-05 0.006571046669425702\n"
     ]
    }
   ],
   "source": [
    "x_vel_mean = np.nanmean([item for sublist in real_x_vels for item in sublist])\n",
    "x_vel_std = np.nanstd([item for sublist in real_x_vels for item in sublist])\n",
    "print(x_vel_mean, x_vel_std)\n",
    "\n",
    "y_vel_mean = np.nanmean([item for sublist in real_y_vels for item in sublist])\n",
    "y_vel_std = np.nanstd([item for sublist in real_y_vels for item in sublist])\n",
    "print(y_vel_mean, y_vel_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833fa329",
   "metadata": {},
   "source": [
    "### velocity\n",
    "#### not normlized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df8b426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 5.56\n",
      "JS(real || Gauss): 34.43\n",
      "JS(real || real): 0.03\n",
      "JS(real || EyeSyn): 12.27\n",
      "JS(real || stat): 53.49\n",
      "JS(real || VAE): 38.06\n"
     ]
    }
   ],
   "source": [
    "real   = np.array([item for sublist in real_vels for item in sublist])\n",
    "real_2 = np.array([item for sublist in real_vels_2 for item in sublist])\n",
    "fake   = np.array([item for sublist in fake_vels for item in sublist])\n",
    "gauss  = np.array([item for sublist in gauss_vels for item in sublist])\n",
    "eyesyn = np.array([item for sublist in eyesyn_vels for item in sublist])\n",
    "stat   = np.array([item for sublist in fix_vels_statistical for item in sublist])\n",
    "f_vae  = np.array([item for sublist in vae_vels for item in sublist])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe94ea",
   "metadata": {},
   "source": [
    "##### normlized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a86ad36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.029\n",
      "JS(real || Gauss): 0.182\n",
      "JS(real || real): 0.0\n",
      "JS(real || EyeSyn): 0.064\n",
      "JS(real || stat): 0.283\n",
      "JS(real || VAE): 0.201\n"
     ]
    }
   ],
   "source": [
    "real   = np.array([item for sublist in real_vels for item in sublist])\n",
    "real_2 = np.array([item for sublist in real_vels_2 for item in sublist])\n",
    "fake   = np.array([item for sublist in fake_vels for item in sublist])\n",
    "gauss  = np.array([item for sublist in gauss_vels for item in sublist])\n",
    "eyesyn = np.array([item for sublist in eyesyn_vels for item in sublist])\n",
    "stat   = np.array([item for sublist in fix_vels_statistical for item in sublist])\n",
    "f_vae  = np.array([item for sublist in vae_vels for item in sublist])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de296066",
   "metadata": {},
   "source": [
    "### mean velocity\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e3c5b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 1208.91\n",
      "JS(real || Gauss): 2683.12\n",
      "JS(real || real): 109.9\n",
      "JS(real || EyeSyn): 3213.22\n",
      "JS(real || stat): 2779.17\n",
      "JS(real || VAE): 3869.9\n"
     ]
    }
   ],
   "source": [
    "real  = np.array([np.mean(a) for a in real_vels])\n",
    "real_2 = np.array([np.mean(a) for a in real_vels_2])\n",
    "fake  = np.array([np.mean(a) for a in fake_vels])\n",
    "gauss = np.array([np.mean(a) for a in gauss_vels])\n",
    "eyesyn = np.array([np.mean(a) for a in eyesyn_vels])\n",
    "f_vae  = np.array([np.mean(a) for a in vae_vels])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5e372",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046a37af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.295\n",
      "JS(real || Gauss): 0.656\n",
      "JS(real || real): 0.026\n",
      "JS(real || EyeSyn): 0.785\n",
      "JS(real || stat): 0.679\n",
      "JS(real || VAE): 0.946\n"
     ]
    }
   ],
   "source": [
    "real  = np.array([np.mean(a) for a in real_vels])\n",
    "real_2 = np.array([np.mean(a) for a in real_vels_2])\n",
    "fake  = np.array([np.mean(a) for a in fake_vels])\n",
    "gauss = np.array([np.mean(a) for a in gauss_vels])\n",
    "eyesyn = np.array([np.mean(a) for a in eyesyn_vels])\n",
    "f_vae  = np.array([np.mean(a) for a in vae_vels])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c927102",
   "metadata": {},
   "source": [
    "### dispersion\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c09b180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 45.77\n",
      "JS(real || Gauss): 58.01\n",
      "JS(real || real): 7.65\n",
      "JS(real || EyeSyn): 166.86\n",
      "JS(real || VAE): 121.82\n"
     ]
    }
   ],
   "source": [
    "real   = np.array(real_dispersions)\n",
    "real_2 = np.array(real_dispersions_2)\n",
    "fake   = np.array(fake_dispersions)\n",
    "gauss  = np.array(gauss_dispersions)\n",
    "eyesyn = np.array(eyesyn_dispersions)\n",
    "f_vae  = np.array(vae_dispersions)\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6ed2e",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "320c8924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.271\n",
      "JS(real || Gauss): 0.344\n",
      "JS(real || real): 0.045\n",
      "JS(real || EyeSyn): 0.989\n",
      "JS(real || VAE): 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasse/anaconda3/envs/aeye_tensorflow_minimal/lib/python3.10/site-packages/numpy/lib/histograms.py:906: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    }
   ],
   "source": [
    "real   = np.array(real_dispersions)\n",
    "real_2 = np.array(real_dispersions_2)\n",
    "fake   = np.array(fake_dispersions)\n",
    "gauss  = np.array(gauss_dispersions)\n",
    "eyesyn = np.array(eyesyn_dispersions)\n",
    "f_vae  = np.array(vae_dispersions)\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40971d79",
   "metadata": {},
   "source": [
    "## Evaluate Saccades\n",
    "* peak, mean, median velocity\n",
    "* peak, mean, median acceleration (peak mean)\n",
    "* amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "908f7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "sac_model = eventGAN.eventGAN(model_config_saccade)\n",
    "sac_model.load_model(saccade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3a3e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([sample_size, random_size], seed = seed)\n",
    "gen_saccades = np.array(sac_model.generator(noise, training=False),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00d45b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.032931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.082144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.311250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.010363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.050939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.837081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  60000.000000\n",
       "mean       0.032931\n",
       "std        0.082144\n",
       "min       -0.311250\n",
       "25%       -0.010363\n",
       "50%        0.010359\n",
       "75%        0.050939\n",
       "max        0.837081"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gen_saccades.shape)\n",
    "pd.DataFrame(gen_saccades.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843c9e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:49:28.361098: W tensorflow/tsl/framework/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "vae_model = vae.VAE(vae.get_vae_encoder(64, 2, 2), vae.get_vae_decoder(2, 2))\n",
    "vae_model.load_model('event_model/vae_saccade_10')\n",
    "noise = tf.random.normal([sample_size, 2], seed = seed)\n",
    "vae_saccades = np.array(vae_model.decoder(noise, training=False),dtype=np.float32)\n",
    "vae_saccades = vae_saccades[:,0:30,:] -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c8c68b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.118281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.094478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.037366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.015778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  60000.000000\n",
       "mean      -0.043367\n",
       "std        0.048688\n",
       "min       -0.118281\n",
       "25%       -0.094478\n",
       "50%       -0.037366\n",
       "75%        0.005859\n",
       "max        0.015778"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vae_saccades.shape)\n",
    "pd.DataFrame(vae_saccades.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc4c22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ids        = np.random.permutation(np.arange(saccade_matrix.shape[0]))\n",
    "rand_ids_1      = rand_ids[0:sample_size]\n",
    "rand_ids_2      = rand_ids[sample_size:sample_size+sample_size]\n",
    "\n",
    "rand_ids        = np.arange(saccade_matrix.shape[0])\n",
    "rand_ids        = np.random.permutation(rand_ids)[0:sample_size]\n",
    "orig_saccades   = saccade_matrix[rand_ids_1,:,4:6]\n",
    "orig_saccades[orig_saccades > max_velocity] = max_velocity\n",
    "orig_saccades[orig_saccades < -max_velocity] = -max_velocity\n",
    "\n",
    "orig_saccades_2 = saccade_matrix[rand_ids_2,:,4:6]\n",
    "orig_saccades_2[orig_saccades_2 > max_velocity] = max_velocity\n",
    "orig_saccades_2[orig_saccades_2 < -max_velocity] = -max_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "302eb7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 2)\n",
      "(1000, 30, 2)\n",
      "(103890, 30, 6)\n"
     ]
    }
   ],
   "source": [
    "print(orig_saccades.shape)\n",
    "print(orig_saccades_2.shape)\n",
    "print(saccade_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa485990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 10494.71it/s]\n",
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 12135.91it/s]\n",
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 10880.96it/s]\n",
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 11068.31it/s]\n"
     ]
    }
   ],
   "source": [
    "real_vels_sac, real_x_vels_sac, real_y_vels_sac, real_accs_sac, real_x_accs_sac, real_y_accs_sac, real_amplitudes_sac      = get_saccade_stats(orig_saccades)\n",
    "real_vels_sac_2, real_x_vels_sac_2, real_y_vels_sac_2, real_accs_sac_2, real_x_accs_sac_2, real_y_accs_sac_2, real_amplitudes_sac_2      = get_saccade_stats(orig_saccades_2)\n",
    "fake_vels_sac, fake_x_vels_sac, fake_y_vels_sac, fake_accs_sac, fake_real_x_accs_sac, fake_y_accs_sac, fake_amplitudes_sac = get_saccade_stats(gen_saccades)\n",
    "vae_vels_sac, vae_x_vels_sac, vae_y_vels_sac, vae_accs_sac, vae_x_accs_sac, vae_y_accs_sac, vae_amplitudes_sac = get_saccade_stats(vae_saccades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7af95980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 12680.31it/s]\n"
     ]
    }
   ],
   "source": [
    "x_vel_mean_sac = np.nanmean([item for sublist in real_x_vels_sac for item in sublist])\n",
    "x_vel_std_sac = np.nanstd([item for sublist in real_x_vels_sac for item in sublist])\n",
    "\n",
    "y_vel_mean_sac = np.nanmean([item for sublist in real_y_vels_sac for item in sublist])\n",
    "y_vel_std_sac = np.nanstd([item for sublist in real_y_vels_sac for item in sublist])\n",
    "gauss_saccades = np.concatenate([np.random.normal(x_vel_mean_sac,x_vel_std_sac,(sample_size,sac_window_size,1)),\n",
    "                                np.random.normal(y_vel_mean_sac,y_vel_std_sac,(sample_size,sac_window_size,1))],axis=2)\n",
    "gauss_vels_sac, gauss_x_vels_sac, gauss_y_vels_sac, gauss_accs_sac, gauss_real_x_accs_sac, gauss_y_accs_sac, gauss_amplitudes_sac = get_saccade_stats(gauss_saccades)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f7b0f",
   "metadata": {},
   "source": [
    "### peak velocity\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee4a3201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 37.29\n",
      "JS(real || Gauss): 43.26\n",
      "JS(real || real): 2.99\n",
      "JS(real || EyeSyn): 101.25\n",
      "JS(real || stat): 39.0\n",
      "JS(real || VAE): 104.4\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.max(a) for a in real_vels_sac])\n",
    "real_2 = np.array([np.max(a) for a in real_vels_sac_2])\n",
    "fake = np.array([np.max(a) for a in fake_vels_sac])\n",
    "gauss = np.array([np.max(a) for a in gauss_vels_sac])\n",
    "stat   = np.array([np.max(a) for a in sac_vels_statistical])\n",
    "f_vae  = np.array([np.max(a) for a in vae_vels_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07316f0",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ce24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.33\n",
      "JS(real || Gauss): 0.382\n",
      "JS(real || real): 0.026\n",
      "JS(real || EyeSyn): 0.896\n",
      "JS(real || stat): 0.346\n",
      "JS(real || VAE): 0.924\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.max(a) for a in real_vels_sac])\n",
    "real_2 = np.array([np.max(a) for a in real_vels_sac_2])\n",
    "fake = np.array([np.max(a) for a in fake_vels_sac])\n",
    "gauss = np.array([np.max(a) for a in gauss_vels_sac])\n",
    "stat   = np.array([np.max(a) for a in sac_vels_statistical])\n",
    "f_vae  = np.array([np.max(a) for a in vae_vels_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8688f",
   "metadata": {},
   "source": [
    "### mean velocity\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6936be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 27.08\n",
      "JS(real || Gauss): 66.7\n",
      "JS(real || real): 2.52\n",
      "JS(real || EyeSyn): 95.26\n",
      "JS(real || stat): 26.75\n",
      "JS(real || VAE): 109.48\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.mean(a) for a in real_vels_sac])\n",
    "real_2 = np.array([np.mean(a) for a in real_vels_sac_2])\n",
    "fake = np.array([np.mean(a) for a in fake_vels_sac])\n",
    "gauss = np.array([np.mean(a) for a in gauss_vels_sac])\n",
    "stat   = np.array([np.mean(a) for a in sac_vels_statistical])\n",
    "f_vae = np.array([np.mean(a) for a in vae_vels_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d677e",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8435552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.23\n",
      "JS(real || Gauss): 0.566\n",
      "JS(real || real): 0.021\n",
      "JS(real || EyeSyn): 0.808\n",
      "JS(real || stat): 0.226\n",
      "JS(real || VAE): 0.929\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.mean(a) for a in real_vels_sac])\n",
    "real_2 = np.array([np.mean(a) for a in real_vels_sac_2])\n",
    "fake = np.array([np.mean(a) for a in fake_vels_sac])\n",
    "gauss = np.array([np.mean(a) for a in gauss_vels_sac])\n",
    "stat   = np.array([np.mean(a) for a in sac_vels_statistical])\n",
    "f_vae = np.array([np.mean(a) for a in vae_vels_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0bf729",
   "metadata": {},
   "source": [
    "### peak acceleration\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9834c63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 19.25\n",
      "JS(real || Gauss): 55.91\n",
      "JS(real || real): 17.21\n",
      "JS(real || EyeSyn): 64.52\n",
      "JS(real || stat): 67.35\n",
      "JS(real || VAE): 66.78\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.max(a) for a in real_accs_sac])\n",
    "real_2 = np.array([np.mean(a) for a in real_accs_sac])\n",
    "fake = np.array([np.max(a) for a in fake_accs_sac])\n",
    "gauss = np.array([np.max(a) for a in gauss_accs_sac])\n",
    "stat   = np.array([np.max(a) for a in sac_acc_statistical])\n",
    "f_vae = np.array([np.max(a) for a in vae_accs_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0627c8a",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8592026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.263\n",
      "JS(real || Gauss): 0.763\n",
      "JS(real || real): 0.235\n",
      "JS(real || EyeSyn): 0.881\n",
      "JS(real || stat): 0.921\n",
      "JS(real || VAE): 0.912\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.max(a) for a in real_accs_sac])\n",
    "real_2 = np.array([np.mean(a) for a in real_accs_sac])\n",
    "fake = np.array([np.max(a) for a in fake_accs_sac])\n",
    "gauss = np.array([np.max(a) for a in gauss_accs_sac])\n",
    "stat   = np.array([np.max(a) for a in sac_acc_statistical])\n",
    "f_vae = np.array([np.max(a) for a in vae_accs_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732bc280",
   "metadata": {},
   "source": [
    "### mean acceleration\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1df4dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 31.95\n",
      "JS(real || Gauss): 60.9\n",
      "JS(real || real): 4.55\n",
      "JS(real || EyeSyn): 117.68\n",
      "JS(real || stat): 124.19\n",
      "JS(real || VAE): 131.52\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.mean(a) for a in real_accs_sac])\n",
    "real_2 = np.array([np.mean(a) for a in real_accs_sac_2])\n",
    "fake = np.array([np.mean(a) for a in fake_accs_sac])\n",
    "gauss = np.array([np.mean(a) for a in gauss_accs_sac])\n",
    "stat   = np.array([np.mean(a) for a in sac_acc_statistical])\n",
    "f_vae = np.array([np.mean(a) for a in vae_accs_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686fbf6e",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c74cfa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.22\n",
      "JS(real || Gauss): 0.42\n",
      "JS(real || real): 0.031\n",
      "JS(real || EyeSyn): 0.811\n",
      "JS(real || stat): 0.856\n",
      "JS(real || VAE): 0.907\n"
     ]
    }
   ],
   "source": [
    "real = np.array([np.mean(a) for a in real_accs_sac])\n",
    "real_2 = np.array([np.mean(a) for a in real_accs_sac_2])\n",
    "fake = np.array([np.mean(a) for a in fake_accs_sac])\n",
    "gauss = np.array([np.mean(a) for a in gauss_accs_sac])\n",
    "stat   = np.array([np.mean(a) for a in sac_acc_statistical])\n",
    "f_vae = np.array([np.mean(a) for a in vae_accs_sac])\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(eyesyn) + list(stat) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "stat_counts,_  = np.histogram(stat, bins = bins, density=True)\n",
    "stat_counts /= np.sum(stat_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_stat = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(stat_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || stat): ' + str(np.round(js_divergence_vel_stat,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d8f2c",
   "metadata": {},
   "source": [
    "### amplitude\n",
    "#### not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87e99b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 1.12\n",
      "JS(real || Gauss): 2.07\n",
      "JS(real || real): 0.16\n",
      "JS(real || EyeSyn): 0.81\n",
      "JS(real || VAE): 4.78\n"
     ]
    }
   ],
   "source": [
    "real = real_amplitudes_sac\n",
    "real_2 = np.array([np.mean(a) for a in real_amplitudes_sac_2])\n",
    "fake = fake_amplitudes_sac\n",
    "gauss = gauss_amplitudes_sac\n",
    "f_vae = vae_amplitudes_sac\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 2)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=2)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 2)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 2)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1920b0",
   "metadata": {},
   "source": [
    "#### normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0297b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS(real || GAN): 0.214\n",
      "JS(real || Gauss): 0.395\n",
      "JS(real || real): 0.03\n",
      "JS(real || EyeSyn): 0.947\n",
      "JS(real || VAE): 0.915\n"
     ]
    }
   ],
   "source": [
    "real = real_amplitudes_sac\n",
    "real_2 = np.array([np.mean(a) for a in real_amplitudes_sac_2])\n",
    "fake = fake_amplitudes_sac\n",
    "gauss = gauss_amplitudes_sac\n",
    "f_vae = vae_amplitudes_sac\n",
    "\n",
    "min_val = np.min(list(real) + list(fake) + list(gauss) + list(real_2) + list(f_vae))\n",
    "max_val = np.max(list(real) + list(fake) + list(gauss) + list(real_2) + list(f_vae))\n",
    "num_bins = 100\n",
    "epsilon = 0.00001\n",
    "bins = np.linspace(min_val,max_val,num_bins)\n",
    "\n",
    "real_counts,_   = np.histogram(real, bins = bins, density=True)\n",
    "real_counts /= np.sum(real_counts)\n",
    "real_counts_2,_   = np.histogram(real_2, bins = bins, density=True)\n",
    "real_counts_2 /= np.sum(real_counts_2)\n",
    "fake_counts,_   = np.histogram(fake, bins = bins, density=True)\n",
    "fake_counts /= np.sum(fake_counts)\n",
    "gauss_counts,_  = np.histogram(gauss, bins = bins, density=True)\n",
    "gauss_counts /= np.sum(gauss_counts)\n",
    "eyesyn_counts,_  = np.histogram(eyesyn, bins = bins, density=True)\n",
    "eyesyn_counts /= np.sum(eyesyn_counts)\n",
    "vae_counts,_  = np.histogram(f_vae, bins = bins, density=True)\n",
    "vae_counts /= np.sum(vae_counts)\n",
    "\n",
    "\n",
    "js_divergence_vel_fake  = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(fake_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_gauss = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(gauss_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_real = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(real_counts_2) + epsilon)\n",
    "\n",
    "js_divergence_vel_syneye = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(eyesyn_counts) + epsilon)\n",
    "\n",
    "js_divergence_vel_vae = js_divergence(np.array(real_counts)  + epsilon,\n",
    "                                      np.array(vae_counts) + epsilon)\n",
    "\n",
    "\n",
    "print('JS(real || GAN): ' + str(np.round(js_divergence_vel_fake,decimals = 3)))\n",
    "print('JS(real || Gauss): ' + str(np.round(js_divergence_vel_gauss,decimals=3)))\n",
    "print('JS(real || real): ' + str(np.round(js_divergence_vel_real,decimals = 3)))\n",
    "print('JS(real || EyeSyn): ' + str(np.round(js_divergence_vel_syneye,decimals = 3)))\n",
    "print('JS(real || VAE): ' + str(np.round(js_divergence_vel_vae,decimals = 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
