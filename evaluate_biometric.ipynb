{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2d39ed",
   "metadata": {},
   "source": [
    "## Evaluate Biometric Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "from sklearn import metrics\n",
    "from scipy.stats import ttest_ind, ttest_1samp\n",
    "import time\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c04df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "dst_dir = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b308c8f1",
   "metadata": {},
   "source": [
    "### Evaluate GazeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0b77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_dict_for_setting(inspect_key = 'normalized Ethnicity',\n",
    "                        inspect_list = ['Caucasian','Black','Asian','Hispanic'],                        \n",
    "                        demo_dict = dict(),\n",
    "                        result_list = [],\n",
    "                        only_equal = False,\n",
    "                        verbose = 1,\n",
    "                        ):\n",
    "    if verbose == 1:\n",
    "        disable = False\n",
    "    else:\n",
    "        disable = True\n",
    "    metric_dict = dict()\n",
    "    for fold_nr in tqdm(np.arange(len(result_list)), disable = disable):\n",
    "        cur_data = result_list[fold_nr]\n",
    "        scores = cur_data['scores']\n",
    "        labels = cur_data['labels']\n",
    "        person_one = cur_data['person_one']\n",
    "        person_two = cur_data['person_two']        \n",
    "        \n",
    "        person_one_list = person_one\n",
    "        person_two_list = person_two\n",
    "        \n",
    "        if demo_dict is not None:\n",
    "            person_one_label = []\n",
    "            for i in range(len(person_one_list)):\n",
    "                if inspect_key is not None:\n",
    "                    person_one_label.append(demo_dict[inspect_key][person_one_list[i]])\n",
    "                else:\n",
    "                    person_one_label.append(demo_dict[person_one_list[i]])\n",
    "\n",
    "            person_two_label = []\n",
    "            for i in range(len(person_two_list)):\n",
    "                if inspect_key is not None:            \n",
    "                    person_two_label.append(demo_dict[inspect_key][person_two_list[i]])\n",
    "                else:\n",
    "                    person_two_label.append(demo_dict[person_two_list[i]])\n",
    "        \n",
    "        # all persons\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(labels, scores, pos_label=1)\n",
    "        if 'all' not in metric_dict:\n",
    "            metric_dict['all'] = {'fprs':[],\n",
    "                                  'tprs':[],\n",
    "                                  'thresholds':[]}\n",
    "        metric_dict['all']['fprs'].append(fpr)\n",
    "        metric_dict['all']['tprs'].append(tpr)\n",
    "        metric_dict['all']['thresholds'].append(thresholds)\n",
    "        \n",
    "        if demo_dict is not None:\n",
    "            # all combinations\n",
    "            for key_1 in inspect_list:\n",
    "                for key_2 in inspect_list:\n",
    "                    if only_equal:\n",
    "                        if key_1 != key_2:\n",
    "                            continue\n",
    "                    use_ids = []\n",
    "                    for i in range(len(person_one_label)):\n",
    "                        # all instances matching the criterion\n",
    "                        if person_one_label[i] == key_1 and person_two_label[i] == key_2:\n",
    "                            use_ids.append(i)\n",
    "                        # all matches; matching the criterion\n",
    "                        if person_one_label[i] == key_1 and labels[i] == 1:\n",
    "                            use_ids.append(i)\n",
    "                    use_ids = list(set(use_ids))\n",
    "                    fpr, tpr, thresholds = metrics.roc_curve(np.array(labels)[use_ids],\n",
    "                                                             np.array(scores)[use_ids],\n",
    "                                                             pos_label=1)\n",
    "                    cur_key = key_1 + ' - ' + str(key_2)\n",
    "                    if cur_key not in metric_dict:\n",
    "                        metric_dict[cur_key] = {'fprs':[],\n",
    "                                              'tprs':[],\n",
    "                                              'thresholds':[]}\n",
    "                    metric_dict[cur_key]['fprs'].append(fpr)\n",
    "                    metric_dict[cur_key]['tprs'].append(tpr)\n",
    "                    metric_dict[cur_key]['thresholds'].append(thresholds)\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff22ab6",
   "metadata": {},
   "source": [
    "## GazeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a519dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of models\n",
    "to_eval_files = [   dst_dir + '/EKYT_fold0_biometric__dataset_gazebase_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    dst_dir + '/ekyt_random_window_size_5000_sd_0.1_sd_factor_1.25_embedding_size_128_stimulus_video_model_random_-1baseline_1000_fold0_biometric__dataset_gazebase_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    dst_dir + '/CLRGAZE_fold0_biometric__dataset_gazebase_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    dst_dir + '/clrgaze_random_window_size_5000_sd_0.1_sd_factor_1.25_embedding_size_512_stimulus_video_model_random_-1baseline_1000_fold0_biometric__dataset_gazebase_max_rounds4_num_folds5_window_size1.npz',\n",
    "                ]\n",
    "\n",
    "to_eval_names = ['EKYT (w/o pre-training)',\n",
    "                 'EKYT (CP SP-EyeGAN) fine-tuning',\n",
    "                 'CLRGaze (w/o pre-training)',\n",
    "                 'CLRGaze (CP SP-EyeGAN) fine-tuning',\n",
    "                 ]\n",
    "\n",
    "# params\n",
    "window_size = 1\n",
    "plot_points = 1000\n",
    "xscale = 'log'\n",
    "plot_random = True\n",
    "plot_statistics = True\n",
    "fontsize=14\n",
    "inspect_thresholds = [0.1,0.01,0.001]\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a90bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EKYT (w/o pre-training) & 0.165 $ \\pm$ 0.004*\\\\\n",
      "EKYT (CP SP-EyeGAN) fine-tuning & 0.169 $ \\pm$ 0.003*\\\\\n",
      "EKYT (CP SP-EyeGAN) zero-shot &  0.495 $ \\pm$ 0.004\\\\\n",
      "CLRGaze (w/o pre-training) & 0.181 $ \\pm$ 0.003*\\\\\n",
      "CLRGaze (CP SP-EyeGAN) fine-tuning & 0.188 $ \\pm$ 0.003*\\\\\n",
      "CLRGaze (CP SP-EyeGAN) zero-shot &  0.493 $ \\pm$ 0.003\\\\\n"
     ]
    }
   ],
   "source": [
    "decimals = 3\n",
    "for m_i in tqdm(np.arange(len(to_eval_files)), disable = True):\n",
    "    result_list = []\n",
    "    start = time.time()\n",
    "    for f_i in tqdm(np.arange(folds), disable = True):\n",
    "        try:\n",
    "            cur_result = np.load(to_eval_files[m_i].replace('fold0','fold' + str(f_i)))\n",
    "            result_list.append({'scores':cur_result['scores'],\n",
    "                                'labels':cur_result['labels'],\n",
    "                                'person_one':cur_result['person_one'],\n",
    "                                'person_two':cur_result['person_two'],\n",
    "                                })\n",
    "        except:\n",
    "            continue\n",
    "    end = time.time() - start    \n",
    "    #print('time to load the data: ' + str(end) + ' size: ' + str(len(result_list)))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    metric_dict = get_metric_dict_for_setting(  inspect_key = None,\n",
    "                                                inspect_list = [],                        \n",
    "                                                demo_dict = None,\n",
    "                                                result_list = result_list,\n",
    "                                                verbose = 0,\n",
    "                                              )\n",
    "    \n",
    "    \n",
    "\n",
    "    fprs = metric_dict['all']['fprs']\n",
    "    tprs = metric_dict['all']['tprs']\n",
    "    eers = []\n",
    "    for i in range(len(fprs)):\n",
    "        key_fmr = fprs[i]\n",
    "        key_fnmr = 1 - tprs[i]\n",
    "        cur_inter = interpolate.interp1d(key_fmr,key_fnmr)\n",
    "        fprs_inter = np.linspace(0, 1, plot_points)\n",
    "        fnrs_inter = cur_inter(fprs_inter)\n",
    "        cur_eer = fprs_inter[np.nanargmin(np.absolute((fnrs_inter - fprs_inter)))]\n",
    "        eers.append(cur_eer)\n",
    "    better_random_pvalue = ttest_1samp(a=1. - np.array(eers),popmean=0.5,alternative = 'greater').pvalue\n",
    "    if better_random_pvalue < 0.05:\n",
    "        cur_p_value_add_str = '*'\n",
    "    else:\n",
    "        cur_p_value_add_str = ''\n",
    "    print(to_eval_names[m_i] + ' & ' + str(np.round(np.mean(eers),decimals=decimals)) +\\\n",
    "                                    ' $ \\pm$ ' + str(np.round(np.std(eers) / np.sqrt(len(eers)),decimals=decimals)) +\\\n",
    "             cur_p_value_add_str + '\\\\\\\\')\n",
    "    \n",
    "    if 'fine-tuning' in to_eval_names[m_i]:\n",
    "        result_list = []\n",
    "        start = time.time()\n",
    "        for f_i in tqdm(np.arange(folds), disable = True):\n",
    "            try:\n",
    "                cur_result = np.load(to_eval_files[m_i].replace('fold0','fold' + str(f_i)))\n",
    "                result_list.append({'scores':cur_result['scores_zero_shot'],\n",
    "                                    'labels':cur_result['labels_zero_shot'],\n",
    "                                    'person_one':cur_result['person_one_zero_shot'],\n",
    "                                    'person_two':cur_result['person_two_zero_shot'],\n",
    "                                    })\n",
    "            except:\n",
    "                continue\n",
    "        end = time.time() - start    \n",
    "        #print('time to load the data: ' + str(end) + ' size: ' + str(len(result_list)))\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        metric_dict = get_metric_dict_for_setting(  inspect_key = None,\n",
    "                                                    inspect_list = [],                        \n",
    "                                                    demo_dict = None,\n",
    "                                                    result_list = result_list,\n",
    "                                                    verbose = 0,\n",
    "                                                  )\n",
    "\n",
    "\n",
    "        print_name = to_eval_names[m_i].replace('fine-tuning','zero-shot')\n",
    "        fprs = metric_dict['all']['fprs']\n",
    "        tprs = metric_dict['all']['tprs']\n",
    "        eers = []\n",
    "        for i in range(len(fprs)):\n",
    "            key_fmr = fprs[i]\n",
    "            key_fnmr = 1 - tprs[i]\n",
    "            cur_inter = interpolate.interp1d(key_fmr,key_fnmr)\n",
    "            fprs_inter = np.linspace(0, 1, plot_points)\n",
    "            fnrs_inter = cur_inter(fprs_inter)\n",
    "            cur_eer = fprs_inter[np.nanargmin(np.absolute((fnrs_inter - fprs_inter)))]\n",
    "            eers.append(cur_eer)\n",
    "        better_random_pvalue = ttest_1samp(a=1. - np.array(eers),popmean=0.5,alternative = 'greater').pvalue\n",
    "        if better_random_pvalue < 0.05:\n",
    "            cur_p_value_add_str = '*'\n",
    "        else:\n",
    "            cur_p_value_add_str = ''\n",
    "        print(print_name + ' &  ' + str(np.round(np.mean(eers),decimals=decimals)) +\\\n",
    "                                        ' $ \\pm$ ' + str(np.round(np.std(eers) / np.sqrt(len(eers)),decimals=decimals)) +\\\n",
    "                     cur_p_value_add_str+ '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf6eff",
   "metadata": {},
   "source": [
    "## JuDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec75541",
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of models\n",
    "to_eval_files = [   dst_dir + '/EKYT_fold0_biometric__dataset_judo_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    dst_dir + '/ekyt_random_window_size_5000_sd_0.1_sd_factor_1.25_embedding_size_128_stimulus_video_model_random_-1baseline_1000_fold0_biometric__dataset_judo_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    dst_dir + '/CLRGAZE_fold0_biometric__dataset_judo_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    dst_dir + '/clrgaze_random_window_size_5000_sd_0.1_sd_factor_1.25_embedding_size_512_stimulus_video_model_random_-1baseline_1000_fold0_biometric__dataset_judo_max_rounds4_num_folds5_window_size1.npz',\n",
    "                    ]\n",
    "\n",
    "to_eval_names = ['EKYT (w/o pre-training)',\n",
    "                 'EKYT (CP SP-EyeGAN) fine-tuning',\n",
    "                 'CLRGaze (w/o pre-training)',\n",
    "                 'CLRGaze (CP SP-EyeGAN) fine-tuning',                 \n",
    "                 ]\n",
    "\n",
    "\n",
    "\n",
    "# params\n",
    "window_size = 1\n",
    "plot_points = 1000\n",
    "xscale = 'log'\n",
    "plot_random = True\n",
    "plot_statistics = True\n",
    "fontsize=14\n",
    "inspect_thresholds = [0.1,0.01,0.001]\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b59530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EKYT (w/o pre-training) & 0.112 $ \\pm$ 0.003*\\\\\n",
      "EKYT (CP SP-EyeGAN) fine-tuning & 0.114 $ \\pm$ 0.003*\\\\\n",
      "EKYT (CP SP-EyeGAN) zero-shot &  0.49 $ \\pm$ 0.002*\\\\\n",
      "CLRGaze (w/o pre-training) & 0.109 $ \\pm$ 0.002*\\\\\n",
      "CLRGaze (CP SP-EyeGAN) fine-tuning & 0.124 $ \\pm$ 0.004*\\\\\n",
      "CLRGaze (CP SP-EyeGAN) zero-shot &  0.462 $ \\pm$ 0.002*\\\\\n"
     ]
    }
   ],
   "source": [
    "decimals = 3\n",
    "for m_i in tqdm(np.arange(len(to_eval_files)), disable = True):\n",
    "    result_list = []\n",
    "    start = time.time()\n",
    "    for f_i in tqdm(np.arange(folds), disable = True):\n",
    "        try:\n",
    "            cur_result = np.load(to_eval_files[m_i].replace('fold0','fold' + str(f_i)))\n",
    "            result_list.append({'scores':cur_result['scores'],\n",
    "                                'labels':cur_result['labels'],\n",
    "                                'person_one':cur_result['person_one'],\n",
    "                                'person_two':cur_result['person_two'],\n",
    "                                })\n",
    "        except:\n",
    "            continue\n",
    "    end = time.time() - start    \n",
    "    #print('time to load the data: ' + str(end) + ' size: ' + str(len(result_list)))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    metric_dict = get_metric_dict_for_setting(  inspect_key = None,\n",
    "                                                inspect_list = [],                        \n",
    "                                                demo_dict = None,\n",
    "                                                result_list = result_list,\n",
    "                                                verbose = 0,\n",
    "                                              )\n",
    "    \n",
    "    \n",
    "\n",
    "    fprs = metric_dict['all']['fprs']\n",
    "    tprs = metric_dict['all']['tprs']\n",
    "    eers = []\n",
    "    for i in range(len(fprs)):\n",
    "        key_fmr = fprs[i]\n",
    "        key_fnmr = 1 - tprs[i]\n",
    "        cur_inter = interpolate.interp1d(key_fmr,key_fnmr)\n",
    "        fprs_inter = np.linspace(0, 1, plot_points)\n",
    "        fnrs_inter = cur_inter(fprs_inter)\n",
    "        cur_eer = fprs_inter[np.nanargmin(np.absolute((fnrs_inter - fprs_inter)))]\n",
    "        eers.append(cur_eer)\n",
    "    better_random_pvalue = ttest_1samp(a=1. - np.array(eers),popmean=0.5,alternative = 'greater').pvalue\n",
    "    if better_random_pvalue < 0.05:\n",
    "        cur_p_value_add_str = '*'\n",
    "    else:\n",
    "        cur_p_value_add_str = ''\n",
    "    print(to_eval_names[m_i] + ' & ' + str(np.round(np.mean(eers),decimals=decimals)) +\\\n",
    "                                    ' $ \\pm$ ' + str(np.round(np.std(eers) / np.sqrt(len(eers)),decimals=decimals)) +\\\n",
    "             cur_p_value_add_str + '\\\\\\\\')\n",
    "    \n",
    "    if 'fine-tuning' in to_eval_names[m_i]:\n",
    "        result_list = []\n",
    "        start = time.time()\n",
    "        for f_i in tqdm(np.arange(folds), disable = True):\n",
    "            try:\n",
    "                cur_result = np.load(to_eval_files[m_i].replace('fold0','fold' + str(f_i)))\n",
    "                result_list.append({'scores':cur_result['scores_zero_shot'],\n",
    "                                    'labels':cur_result['labels_zero_shot'],\n",
    "                                    'person_one':cur_result['person_one_zero_shot'],\n",
    "                                    'person_two':cur_result['person_two_zero_shot'],\n",
    "                                    })\n",
    "            except:\n",
    "                continue\n",
    "        end = time.time() - start    \n",
    "        #print('time to load the data: ' + str(end) + ' size: ' + str(len(result_list)))\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        metric_dict = get_metric_dict_for_setting(  inspect_key = None,\n",
    "                                                    inspect_list = [],                        \n",
    "                                                    demo_dict = None,\n",
    "                                                    result_list = result_list,\n",
    "                                                    verbose = 0,\n",
    "                                                  )\n",
    "\n",
    "\n",
    "        print_name = to_eval_names[m_i].replace('fine-tuning','zero-shot')\n",
    "        fprs = metric_dict['all']['fprs']\n",
    "        tprs = metric_dict['all']['tprs']\n",
    "        eers = []\n",
    "        for i in range(len(fprs)):\n",
    "            key_fmr = fprs[i]\n",
    "            key_fnmr = 1 - tprs[i]\n",
    "            cur_inter = interpolate.interp1d(key_fmr,key_fnmr)\n",
    "            fprs_inter = np.linspace(0, 1, plot_points)\n",
    "            fnrs_inter = cur_inter(fprs_inter)\n",
    "            cur_eer = fprs_inter[np.nanargmin(np.absolute((fnrs_inter - fprs_inter)))]\n",
    "            eers.append(cur_eer)\n",
    "        better_random_pvalue = ttest_1samp(a=1. - np.array(eers),popmean=0.5,alternative = 'greater').pvalue\n",
    "        if better_random_pvalue < 0.05:\n",
    "            cur_p_value_add_str = '*'\n",
    "        else:\n",
    "            cur_p_value_add_str = ''\n",
    "        print(print_name + ' &  ' + str(np.round(np.mean(eers),decimals=decimals)) +\\\n",
    "                                        ' $ \\pm$ ' + str(np.round(np.std(eers) / np.sqrt(len(eers)),decimals=decimals)) +\\\n",
    "                     cur_p_value_add_str+ '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8db65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
